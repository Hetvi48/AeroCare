{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOuFDTBCL9fZ/0mojMxKNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hetvi48/AeroCare/blob/main/All_model_1_aircraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFFpfJICeaD8",
        "outputId": "85e124f6-6204-4c6b-9bab-7b4de9c1355d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "ceGtmzEHWBCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Imports ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 2. Load and prepare NASA dataset ---\n",
        "def load_cmapss_train(path_train):\n",
        "    df = pd.read_csv(path_train, sep='\\s+', header=None, engine='python')\n",
        "    df = df.iloc[:, :26]  # adjust if needed\n",
        "    cols = [\"unit\", \"cycle\"] + [f\"op{i}\" for i in range(1, 4)] + [f\"s{i}\" for i in range(1, 22)]\n",
        "    df.columns = cols\n",
        "    return df\n",
        "\n",
        "def make_rul(df):\n",
        "    df = df.copy()\n",
        "    max_cycle = df.groupby('unit')['cycle'].transform('max')\n",
        "    df['RUL'] = max_cycle - df['cycle']\n",
        "    return df\n",
        "\n",
        "train_path = \"drive/MyDrive/archive/CMaps/train_FD001.txt\"  # update path if needed\n",
        "df = load_cmapss_train(train_path)\n",
        "df = make_rul(df)\n",
        "\n",
        "X = df.drop(columns=['unit', 'RUL'])\n",
        "y = df['RUL']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- 3. Evaluation helper ---\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred) # Removed squared=False\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"MAE: {mae:.3f} | RMSE: {rmse:.3f} | R²: {r2:.3f}\")\n",
        "    return mae, rmse, r2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW40s_-pefhL",
        "outputId": "92041f34-0b67-4420-ef4a-226b5f7c2a0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-1299379496.py:13: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  df = pd.read_csv(path_train, sep='\\s+', header=None, engine='python')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2J3TGWOXVxo",
        "outputId": "3a1fee4e-793e-4d80-e6ec-23f2138c91b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16504, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAbK0O8pXYOB",
        "outputId": "bfd537fd-dbf6-4b44-9d3a-9be0078c0ef1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16504,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uskcoIipXaU5",
        "outputId": "c21f2f5a-f96e-49ab-b67e-d30969d12994"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4127, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cJv3dnxXcFa",
        "outputId": "64d233b4-9fa3-4540-ff8d-b101706a4856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4127,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "f4PuaY-9WGUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "print(\"➡ Linear Regression Results:\")\n",
        "evaluate_model(pipe, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRQhUl4Ue4p-",
        "outputId": "309d9042-fd2e-486e-9f01-6c7f3d1fd4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "➡ Linear Regression Results:\n",
            "MAE: 30.543 | RMSE: 1576.332 | R²: 0.655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30.542623586568503, 1576.3317161165214, 0.6549786818840173)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge"
      ],
      "metadata": {
        "id": "9YyPFZ-yWLYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', Ridge())\n",
        "])\n",
        "\n",
        "param_grid = {'model__alpha': np.logspace(-3, 3, 20)}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, cv=5, n_iter=10,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Ridge params:\", search.best_params_)\n",
        "best_ridge = search.best_estimator_\n",
        "evaluate_model(best_ridge, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF1Iht7je-Q-",
        "outputId": "7b418ee7-f2d9-4b6b-ec72-93b0ea371996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Ridge params: {'model__alpha': np.float64(483.2930238571752)}\n",
            "MAE: 30.542 | RMSE: 1578.547 | R²: 0.654\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30.541750272538817, 1578.5473409897847, 0.6544937345811062)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso"
      ],
      "metadata": {
        "id": "DYw11RalWNTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', Lasso(max_iter=5000))\n",
        "])\n",
        "\n",
        "param_grid = {'model__alpha': np.logspace(-4, 1, 20)}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, cv=5, n_iter=10,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Lasso params:\", search.best_params_)\n",
        "best_lasso = search.best_estimator_\n",
        "evaluate_model(best_lasso, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KU8NzjpfMtQ",
        "outputId": "81d772f7-d459-44f8-b0d2-db8024b014d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Lasso params: {'model__alpha': np.float64(0.8858667904100823)}\n",
            "MAE: 30.485 | RMSE: 1576.569 | R²: 0.655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30.485136841459134, 1576.56894643248, 0.6549267578407005)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elastic net"
      ],
      "metadata": {
        "id": "tH5gdtoNWO2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', ElasticNet(max_iter=5000))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__alpha': np.logspace(-3, 1, 10),\n",
        "    'model__l1_ratio': np.linspace(0, 1, 10)\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=20, cv=5,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best ElasticNet params:\", search.best_params_)\n",
        "best_en = search.best_estimator_\n",
        "evaluate_model(best_en, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkHMSYUqfRsQ",
        "outputId": "8e7d650b-0d52-40a3-930b-e977b8a1a929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 6.356e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+07, tolerance: 6.352e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 6.310e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+07, tolerance: 6.273e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 6.316e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+07, tolerance: 6.356e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+07, tolerance: 6.352e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+07, tolerance: 6.310e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e+07, tolerance: 6.273e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+07, tolerance: 6.316e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+07, tolerance: 6.356e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+07, tolerance: 6.352e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+07, tolerance: 6.310e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 6.273e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 6.316e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+07, tolerance: 6.356e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 6.352e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 6.310e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+07, tolerance: 6.273e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 6.316e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+07, tolerance: 6.356e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 6.352e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+07, tolerance: 6.310e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+07, tolerance: 6.273e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 6.316e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.261e+07, tolerance: 6.356e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+07, tolerance: 6.352e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.244e+07, tolerance: 6.310e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 6.273e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.245e+07, tolerance: 6.316e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ElasticNet params: {'model__l1_ratio': np.float64(0.4444444444444444), 'model__alpha': np.float64(0.05994842503189409)}\n",
            "MAE: 30.541 | RMSE: 1578.970 | R²: 0.654\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30.54143593098906, 1578.9698355074868, 0.654401260634218)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN"
      ],
      "metadata": {
        "id": "mhsGb1qVWS4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', KNeighborsRegressor())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'model__weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, cv=5, n_iter=6,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best KNN params:\", search.best_params_)\n",
        "best_knn = search.best_estimator_\n",
        "evaluate_model(best_knn, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U55oeBBsfgmR",
        "outputId": "d076f44e-085f-4c1d-97fc-177b060a61c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN params: {'model__weights': 'uniform', 'model__n_neighbors': 11}\n",
            "MAE: 27.208 | RMSE: 1458.975 | R²: 0.681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27.20789920038769, 1458.9752006039648, 0.6806652168040874)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVR"
      ],
      "metadata": {
        "id": "eHjtjXdsWVjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', SVR())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__C': [0.1, 1, 10, 50],\n",
        "    'model__epsilon': [0.01, 0.1, 0.5],\n",
        "    'model__kernel': ['rbf', 'poly']\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=6, cv=3,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best SVR params:\", search.best_params_)\n",
        "best_svr = search.best_estimator_\n",
        "evaluate_model(best_svr, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3hI9Qg9f55l",
        "outputId": "62ec3f40-4bb8-4694-8a38-31d5e15ce352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVR params: {'model__kernel': 'rbf', 'model__epsilon': 0.01, 'model__C': 50}\n",
            "MAE: 24.075 | RMSE: 1306.703 | R²: 0.714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24.075251516273227, 1306.7025368319585, 0.7139940616344643)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "Xe0a9pCCWXSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', DecisionTreeRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__max_depth': [5, 10, 15, 20, None],\n",
        "    'model__min_samples_leaf': [1, 3, 5, 10]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=6, cv=5,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best DecisionTree params:\", search.best_params_)\n",
        "best_tree = search.best_estimator_\n",
        "evaluate_model(best_tree, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q91lOoXhgBSl",
        "outputId": "4008ba4a-01c4-4c80-d24b-a11e4f2d9147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best DecisionTree params: {'model__min_samples_leaf': 1, 'model__max_depth': 5}\n",
            "MAE: 27.655 | RMSE: 1438.398 | R²: 0.685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27.654528500505105, 1438.3981645110714, 0.6851690379497919)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "ZYyUJ8K_WaWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_estimators': [100, 200, 400],\n",
        "    'model__max_depth': [10, 20, None],\n",
        "    'model__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=6, cv=3,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best RandomForest params:\", search.best_params_)\n",
        "best_rf = search.best_estimator_\n",
        "evaluate_model(best_rf, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hd3zZQ_hJqt",
        "outputId": "1e560e34-504d-476e-c080-be29b7030eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RandomForest params: {'model__n_estimators': 400, 'model__min_samples_split': 10, 'model__max_depth': 10}\n",
            "MAE: 25.261 | RMSE: 1267.580 | R²: 0.723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25.26061271627884, 1267.580198362392, 0.7225570059998823)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting Regressor"
      ],
      "metadata": {
        "id": "2jTkL8zdWdDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', GradientBoostingRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_estimators': [100, 200, 400],\n",
        "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'model__max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=6, cv=3,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best GBR params:\", search.best_params_)\n",
        "best_gbr = search.best_estimator_\n",
        "evaluate_model(best_gbr, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKqweVIohXzu",
        "outputId": "0ef60427-3147-4c69-a772-91c49ed80010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best GBR params: {'model__n_estimators': 200, 'model__max_depth': 5, 'model__learning_rate': 0.05}\n",
            "MAE: 25.374 | RMSE: 1272.018 | R²: 0.722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25.37357508203386, 1272.018133734694, 0.7215856480704501)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "Yw-2E5V9WhbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', xgb.XGBRegressor(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_estimators': [200, 400],\n",
        "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'model__max_depth': [4, 6, 10],\n",
        "    'model__subsample': [0.8, 1],\n",
        "    'model__colsample_bytree': [0.8, 1]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=10, cv=3,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best XGBoost params:\", search.best_params_)\n",
        "best_xgb = search.best_estimator_\n",
        "evaluate_model(best_xgb, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJkcxi50kH8B",
        "outputId": "2728b4dd-9317-4de0-840c-0d748c2a7635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost params: {'model__subsample': 0.8, 'model__n_estimators': 400, 'model__max_depth': 10, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.8}\n",
            "MAE: 25.017 | RMSE: 1247.761 | R²: 0.727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25.016521453857422, 1247.760986328125, 0.7268949747085571)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# light gbm"
      ],
      "metadata": {
        "id": "V7AbRutqWjeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', lgb.LGBMRegressor(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_estimators': [200, 400],\n",
        "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'model__num_leaves': [31, 50, 100],\n",
        "    'model__max_depth': [-1, 10, 20]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=10, cv=3,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best LightGBM params:\", search.best_params_)\n",
        "best_lgbm = search.best_estimator_\n",
        "evaluate_model(best_lgbm, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxRMroaVluhM",
        "outputId": "eb530ae2-e174-476a-d1d3-563df3ca9440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015418 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015930 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002276 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002147 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015397 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3073\n",
            "[LightGBM] [Info] Number of data points in the train set: 11002, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.755408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3061\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.070981\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3063\n",
            "[LightGBM] [Info] Number of data points in the train set: 11003, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.852677\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3084\n",
            "[LightGBM] [Info] Number of data points in the train set: 16504, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.559683\n",
            "Best LightGBM params: {'model__num_leaves': 31, 'model__n_estimators': 400, 'model__max_depth': -1, 'model__learning_rate': 0.01}\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003235 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3084\n",
            "[LightGBM] [Info] Number of data points in the train set: 16504, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score 107.559683\n",
            "MAE: 25.410 | RMSE: 1260.178 | R²: 0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25.41042329544266, 1260.1782220903324, 0.7241771216036847)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Regressor"
      ],
      "metadata": {
        "id": "qOS5g2wvWoET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', MLPRegressor(max_iter=500, random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__hidden_layer_sizes': [(64,), (128,64), (128,64,32)],\n",
        "    'model__alpha': [0.0001, 0.001, 0.01],\n",
        "    'model__learning_rate_init': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(pipe, param_grid, n_iter=6, cv=3,\n",
        "                            scoring='neg_mean_absolute_error', random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best MLP params:\", search.best_params_)\n",
        "best_mlp = search.best_estimator_\n",
        "evaluate_model(best_mlp, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVvILiB1maRB",
        "outputId": "cef0fbe8-dbf4-4ac4-db2b-55a583f92c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best MLP params: {'model__learning_rate_init': 0.001, 'model__hidden_layer_sizes': (64,), 'model__alpha': 0.0001}\n",
            "MAE: 25.086 | RMSE: 1237.018 | R²: 0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25.085881138659076, 1237.017895880233, 0.7292463631822853)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "FhM6qyWDWqjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"Model\": [\"LinearRegression\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"KNeighborsRegressor\", \"SVR\", \"DecisionTreeRegressor\", \"RandomForestRegressor\", \"GradientBoostingRegressor\", \"xgb\", \"lgb\", \"MLPRegressor\"],\n",
        "    \"MAE\": [30.542623586568503, 30.541750272538817, 30.485136841459134, 30.54143593098906, 27.20789920038769, 24.075251516273227, 27.654528500505105, 25.26061271627884, 25.37357508203386, 25.016521453857422, 25.41042329544266, 25.085881138659076],\n",
        "    \"RMSE\": [1576.3317161165214, 1578.5473409897847, 1576.56894643248, 1578.9698355074868, 1458.9752006039648, 1306.7025368319585, 1438.3981645110714, 1267.580198362392, 1272.018133734694, 1247.760986328125, 1260.1782220903324, 1237.017895880233],\n",
        "    \"R2\": [0.6549786818840173, 0.6544937345811062, 0.6549267578407005, 0.654401260634218, 0.6806652168040874, 0.7139940616344643, 0.6851690379497919, 0.7225570059998823, 0.7215856480704501, 0.7268949747085571, 0.7241771216036847, 0.7292463631822853]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvgJWNaVqXNb",
        "outputId": "93c8d6f3-772c-45ec-e133-fbca41299fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Model        MAE         RMSE        R2\n",
            "0            LinearRegression  30.542624  1576.331716  0.654979\n",
            "1                       Ridge  30.541750  1578.547341  0.654494\n",
            "2                       Lasso  30.485137  1576.568946  0.654927\n",
            "3                  ElasticNet  30.541436  1578.969836  0.654401\n",
            "4         KNeighborsRegressor  27.207899  1458.975201  0.680665\n",
            "5                         SVR  24.075252  1306.702537  0.713994\n",
            "6       DecisionTreeRegressor  27.654529  1438.398165  0.685169\n",
            "7       RandomForestRegressor  25.260613  1267.580198  0.722557\n",
            "8   GradientBoostingRegressor  25.373575  1272.018134  0.721586\n",
            "9                         xgb  25.016521  1247.760986  0.726895\n",
            "10                        lgb  25.410423  1260.178222  0.724177\n",
            "11               MLPRegressor  25.085881  1237.017896  0.729246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "res = results_df.copy()\n",
        "res = res.sort_values('MAE')\n",
        "print(res[['Model','MAE','RMSE','R2']])\n",
        "res['MAE'].plot.barh(figsize=(8,6))\n",
        "plt.xlabel(\"Test MAE (cycles)\")\n",
        "plt.title(\"RUL regression: test MAE by model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "8ztvPvo67p6C",
        "outputId": "4a466627-454d-4219-e985-a4d53ac7d8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Model        MAE         RMSE        R2\n",
            "5                         SVR  24.075252  1306.702537  0.713994\n",
            "9                         xgb  25.016521  1247.760986  0.726895\n",
            "11               MLPRegressor  25.085881  1237.017896  0.729246\n",
            "7       RandomForestRegressor  25.260613  1267.580198  0.722557\n",
            "8   GradientBoostingRegressor  25.373575  1272.018134  0.721586\n",
            "10                        lgb  25.410423  1260.178222  0.724177\n",
            "4         KNeighborsRegressor  27.207899  1458.975201  0.680665\n",
            "6       DecisionTreeRegressor  27.654529  1438.398165  0.685169\n",
            "2                       Lasso  30.485137  1576.568946  0.654927\n",
            "3                  ElasticNet  30.541436  1578.969836  0.654401\n",
            "1                       Ridge  30.541750  1578.547341  0.654494\n",
            "0            LinearRegression  30.542624  1576.331716  0.654979\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARXlJREFUeJzt3Wl4FFX+9vG7E0gnhCQQthAIIQRkXyIIw75KCIuAIoigAQRR4wKIaJxBYMAJMOowKALKOqyyDMiMIoKyiIICwgiobIKJsilLAkE6mNTzwif9t0nC4ummG/h+rquuoatO9/l1V5fTd07VKZtlWZYAAAAAwICftwsAAAAAcPMjWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgjWADATWL06NGy2WzeLgNu0KpVK9WqVcvbZXhcq1at1KpVqz/03IoVK6pfv35urQeAZxEsABRozpw5stlszqVQoUIqV66c+vXrpx9//DFP+4oVK6pz5875vtb27dtls9k0Z84c57rcH8o///yzp94CPOjrr7/W6NGjdeTIEY/28+abb7p8b64m9/s6cODAfLf/+c9/drYp6LvXs2dP2Ww2Pf/88/lu37Bhg8uxcfmyePHia64XAG4VhbxdAADf99e//lUxMTG6ePGitm7dqjlz5mjz5s3as2ePAgMDvV3ebeMvf/mLXnjhBW+X4fT1119rzJgxatWqlSpWrOixft58802VLFnyuv56HRgYqOXLl+vNN99UQECAy7ZFixYpMDBQFy9ezPe5GRkZ+s9//qOKFStq0aJFGj9+fIEjRU8//bTuuuuuPOsbN258zbUCwK2CYAHgqhISEtSgQQNJ0sCBA1WyZElNmDBBq1atUs+ePb1c3W9+/fVX5eTk5PkR6QmWZenixYsKCgryeF+/V6hQIRUqxH+2r0WHDh20atUqrV69Wl27dnWu/+yzz3T48GHdd999Wr58eb7PXb58ubKzszVr1iy1adNGmzZtUsuWLfNt27x5c/Xo0cMj7wEAbjacCgXgujVv3lySdOjQIa/0f+TIEdlsNr3yyiuaNGmSYmNjZbfb9fXXX0uSvv32W/Xo0UPh4eEKDAxUgwYNtGrVqjyv89VXX6lly5YKCgpS+fLlNW7cOM2ePVs2m83l9J7cU7zWrFmjBg0aKCgoSNOnT5cknT17VkOGDFFUVJTsdrsqV66sCRMmKCcnx6WvxYsXq379+goJCVFoaKhq166tf/7zn87tly5d0pgxY1SlShUFBgaqRIkSatasmdauXetsk981Fr/++qvGjh3r/AwqVqyoF198UQ6Hw6Vd7nvYvHmzGjZsqMDAQFWqVEn/+te/8nwuhw4duuq+nTNnju6//35JUuvWrZ2nAG3YsMHZZvXq1WrevLmCg4MVEhKiTp06ae/evS6vc/z4cfXv31/ly5eX3W5X2bJl1bVrV+fnX7FiRe3du1cbN2509nEt5+yXK1dOLVq00MKFC13WL1iwQLVr177i9Q0LFizQ3XffrdatW6t69epasGDBVfv7o3bs2KEmTZooKChIMTExmjZtmnPb+fPnFRwcrGeeeSbP83744Qf5+/srJSWlwNf+/XEyZcoUVapUSUWKFFH79u2VlpYmy7I0duxYlS9fXkFBQeratatOnz6d53XefPNN1axZU3a7XZGRkUpKStLZs2fztHvrrbcUGxuroKAgNWzYUJ988km+dTkcDo0aNUqVK1eW3W5XVFSURowYkec7C+Dmw5++AFy33B99xYsX92ods2fP1sWLF/Xoo4/KbrcrPDxce/fuVdOmTVWuXDm98MILCg4O1pIlS9StWzctX75c3bt3lyT9+OOPzh/EycnJCg4O1owZM2S32/Pta9++ferdu7cGDx6sQYMGqWrVqrpw4YJatmypH3/8UYMHD1aFChX02WefKTk5WceOHdOkSZMkSWvXrlXv3r3Vtm1bTZgwQZL0zTff6NNPP3X+aBw9erRSUlI0cOBANWzYUBkZGdq+fbu+/PJL3X333QV+BgMHDtTcuXPVo0cPPfvss/r888+VkpKib775RitWrHBpe/DgQfXo0UOPPPKIEhMTNWvWLPXr10/169dXzZo1ne3atm0rSVe8dqJFixZ6+umnNXnyZL344ouqXr26JDn/d968eUpMTFR8fLwmTJigCxcuaOrUqWrWrJl27tzpPHXqvvvu0969e/XUU0+pYsWKOnnypNauXavU1FRVrFhRkyZN0lNPPaWiRYvqz3/+sySpTJkyBdb1ew8++KCeeeYZnT9/XkWLFtWvv/6qpUuXatiwYQWeBnX06FGtX79ec+fOlST17t1b//jHP/TGG2/kOxp27ty5fK/TKFGixFUvtD9z5ow6duyonj17qnfv3lqyZIkef/xxBQQEaMCAASpatKi6d++ud955R6+99pr8/f2dz120aJEsy1KfPn2u+jksWLBAWVlZeuqpp3T69GlNnDhRPXv2VJs2bbRhwwY9//zzOnjwoF5//XUNHz5cs2bNcj539OjRGjNmjNq1a6fHH39c+/bt09SpU7Vt2zZ9+umnKly4sCRp5syZGjx4sJo0aaIhQ4bou+++0z333KPw8HBFRUU5Xy8nJ0f33HOPNm/erEcffVTVq1fX7t279Y9//EP79+/XypUrr/p+APgwCwAKMHv2bEuStW7dOuunn36y0tLSrGXLllmlSpWy7Ha7lZaW5tI+Ojra6tSpU76vtW3bNkuSNXv2bOe6UaNGWZKsn3766brqOnz4sCXJCg0NtU6ePOmyrW3btlbt2rWtixcvOtfl5ORYTZo0sapUqeJc99RTT1k2m83auXOnc92pU6es8PBwS5J1+PBhl/clyfrggw9c+ho7dqwVHBxs7d+/32X9Cy+8YPn7+1upqamWZVnWM888Y4WGhlq//vprge+pbt26BX52uXI/r1y7du2yJFkDBw50aTd8+HBLkvXxxx/neQ+bNm1yrjt58qRlt9utZ5991uX50dHRVnR09BVrsSzLWrp0qSXJWr9+vcv6c+fOWcWKFbMGDRrksv748eNWWFiYc/2ZM2csSdbf//73K/ZTs2ZNq2XLlletJ5ckKykpyTp9+rQVEBBgzZs3z7Isy3rvvfcsm81mHTlypMDv3iuvvGIFBQVZGRkZlmVZ1v79+y1J1ooVK1zarV+/3pJU4HLs2LEr1tiyZUtLkvXqq6861zkcDqtevXpW6dKlraysLMuyLGvNmjWWJGv16tUuz69Tp85VP5Pc46RUqVLW2bNnneuTk5MtSVbdunWtS5cuOdf37t3bCggIcB47J0+etAICAqz27dtb2dnZznZvvPGGJcmaNWuWZVmWlZWVZZUuXdqqV6+e5XA4nO3eeustS5JLnfPmzbP8/PysTz75xKXWadOmWZKsTz/91LkuOjraSkxMvOJ7BOBbOBUKwFW1a9dOpUqVUlRUlHr06KHg4GCtWrVK5cuX92pd9913n0qVKuV8fPr0aX388cfq2bOn8y/JP//8s06dOqX4+HgdOHDAOZvVBx98oMaNG6tevXrO54eHhxf4F+CYmBjFx8e7rFu6dKmaN2+u4sWLO/v6+eef1a5dO2VnZ2vTpk2SpGLFiikzM9PltKbLFStWTHv37tWBAweu+f2///77kqRhw4a5rH/22WclSe+9957L+ho1ajhPY5OkUqVKqWrVqvruu+9c2h05csRopqe1a9fq7Nmz6t27t8vn4u/vr0aNGmn9+vWSpKCgIAUEBGjDhg06c+bMH+6vIMWLF1eHDh20aNEiSdLChQvVpEkTRUdHF/icBQsWqFOnTgoJCZEkValSRfXr1y/wdKiXXnpJa9euzbOEh4dftb5ChQpp8ODBzscBAQEaPHiwTp48qR07dkj67diLjIx06X/Pnj366quv1Ldv36t/CJLuv/9+hYWFOR83atRIktS3b1+Xa3YaNWqkrKws5zGybt06ZWVlaciQIfLz+7+fC4MGDVJoaKjz+7V9+3adPHlSjz32mMuoTr9+/Vz6lX47ZqpXr65q1aq5fDfatGkjSc7vBoCbE6dCAbiqKVOm6I477lB6erpmzZqlTZs2FXjK0NW48z4MMTExLo8PHjwoy7I0cuRIjRw5Mt/nnDx5UuXKldP333+f78w9lStXvqa+JOnAgQP66quvXMLN5X1J0hNPPKElS5YoISFB5cqVU/v27dWzZ0916NDB2favf/2runbtqjvuuEO1atVShw4d9NBDD6lOnTr5v3lJ33//vfz8/PLUHBERoWLFiun77793WV+hQoU8r1G8eHG3/6jPDUe5PxYvFxoaKkmy2+2aMGGCnn32WZUpU0Z/+tOf1LlzZz388MOKiIhwSy0PPvigHnroIaWmpmrlypWaOHFigW2/+eYb7dy5Uw8//LAOHjzoXN+qVStNmTJFGRkZztpz1a5dW+3atftDtUVGRio4ONhl3R133CHpt3D3pz/9SX5+furTp4+mTp2qCxcuqEiRIlqwYIECAwOd17hczeX7PffH/u9PUfr9+tzvQ+73p2rVqi7tAgICVKlSJef23P+tUqWKS7vChQurUqVKLusOHDigb7755qrHDICbE8ECwFU1bNjQOStUt27d1KxZMz344IPat2+fihYt6mwXGBioX375Jd/XuHDhgrONu1w+K1PuBdPDhw/PM7qQq6DgcL195fZ39913a8SIEfk+J/dHYunSpbVr1y6tWbNGq1ev1urVqzV79mw9/PDDznP5W7RooUOHDundd9/Vhx9+qBkzZugf//iHpk2bVuD9GHJda1j7/Tn6v2dZ1jU9/1rl7od58+blGxB+/1fyIUOGqEuXLlq5cqXWrFmjkSNHKiUlRR9//LHi4uKMa7nnnntkt9uVmJgoh8NxxVnM5s+fL0kaOnSohg4dmmf78uXL1b9/f+OartfDDz+sv//971q5cqV69+6thQsXqnPnznlGAwpS0H6/Ud+H38vJyVHt2rX12muv5bv98rAD4OZCsABwXXJnomndurXeeOMNl/sqREdHO2dmuty+ffucbTwl96+jhQsXvupfkaOjo13+Kp0rv3UFiY2N1fnz56/pL9YBAQHq0qWLunTpopycHD3xxBOaPn26Ro4c6Qw74eHh6t+/v/r376/z58+rRYsWGj16dIHBIjo6Wjk5OTpw4IDzomlJOnHihM6ePevRz1oqONDExsZK+i1QXctnExsbq2effVbPPvusDhw4oHr16unVV191/tA3GeUKCgpSt27dNH/+fCUkJKhkyZL5trMsSwsXLlTr1q31xBNP5Nk+duxYLViwwK3B4ujRo8rMzHQZtdi/f78kudwXpFatWoqLi9OCBQtUvnx5paam6vXXX3dbHQXJ/f7s27fPZeQhKytLhw8fdu7b3HYHDhxwGaW6dOmSDh8+rLp16zrXxcbG6n//+5/atm3LXeSBWxDXWAC4bq1atVLDhg01adIkl9l1OnbsqB9++CHPzC4Oh0MzZsxQ6dKldeedd3qsrtKlS6tVq1aaPn26jh07lmf7Tz/95Px3fHy8tmzZol27djnXnT59+rqmFu3Zs6e2bNmiNWvW5Nl29uxZ/frrr5KkU6dOuWzz8/NznuKUO8Xm5W2KFi2qypUrX3EKzo4dO0qSc/apXLl/De7UqdM1v5ffu5bpZiU5fxBfPvVofHy8QkND9be//U2XLl3K87zc/XDhwoU8szPFxsYqJCTE5X0HBwfnO73ptRo+fLhGjRpV4OlxkvTpp5/qyJEj6t+/v3r06JFn6dWrl9avX6+jR4/+4Tou9+uvvzqnLZZ++8E+ffp0lSpVSvXr13dp+9BDD+nDDz/UpEmTVKJECSUkJLitjoK0a9dOAQEBmjx5sssoxsyZM5Wenu78fjVo0EClSpXStGnTlJWV5Ww3Z86cPPutZ8+e+vHHH/X222/n6e+XX35RZmamZ94MgBuCEQsAf8hzzz2n+++/X3PmzNFjjz0mSXr00Uc1a9Ys3X///RowYIDi4uJ06tQpvfPOO9qzZ4/+9a9/5Ttl52uvvaYiRYq4rPPz89OLL7543XVNmTJFzZo1U+3atTVo0CBVqlRJJ06c0JYtW/TDDz/of//7nyRpxIgRmj9/vu6++2499dRTzulmK1SooNOnT1/TX1Ofe+45rVq1Sp07d3ZO25qZmandu3dr2bJlOnLkiEqWLKmBAwfq9OnTatOmjcqXL6/vv/9er7/+uurVq+ccaahRo4ZatWql+vXrKzw8XNu3b9eyZcv05JNPFth/3bp1lZiYqLfeektnz55Vy5Yt9cUXX2ju3Lnq1q2bWrdufd2fn3Rt081KUr169eTv768JEyYoPT1ddrtdbdq0UenSpTV16lQ99NBDuvPOO/XAAw+oVKlSSk1N1XvvvaemTZvqjTfe0P79+9W2bVv17NlTNWrUUKFChbRixQqdOHFCDzzwgLOf+vXra+rUqRo3bpwqV66s0qVLF3j9RkGf0+//ap6fBQsWyN/fv8Awds899+jPf/6zFi9e7HKx/CeffJLv1LV16tS54vUx0m/XWEyYMEFHjhzRHXfcoXfeeUe7du3SW2+95ZzGNdeDDz6oESNGaMWKFXr88cfzbPeEUqVKKTk5WWPGjFGHDh10zz33aN++fXrzzTd11113OS8eL1y4sMaNG6fBgwerTZs26tWrlw4fPqzZs2fnucbioYce0pIlS/TYY49p/fr1atq0qbKzs/Xtt99qyZIlznvFALhJeXVOKgA+LXe62W3btuXZlp2dbcXGxlqxsbEu06ieOXPGGjp0qBUTE2MVLlzYCg0NtVq3bp1nukzL+r/pU/Nb/P39C6wrdxrNgqYpPXTokPXwww9bERERVuHCha1y5cpZnTt3tpYtW+bSbufOnVbz5s0tu91ulS9f3kpJSbEmT55sSbKOHz/ubHelaXTPnTtnJScnW5UrV7YCAgKskiVLWk2aNLFeeeUV55Shy5Yts9q3b2+VLl3aCggIsCpUqGANHjzYZUrScePGWQ0bNrSKFStmBQUFWdWqVbNefvll52v8/vP6vUuXLlljxoxxft5RUVFWcnKyy3S7V3oPLVu2zDNt6bVON2tZlvX2229blSpVsvz9/fNMPbt+/XorPj7eCgsLswIDA63Y2FirX79+1vbt2y3Lsqyff/7ZSkpKsqpVq2YFBwdbYWFhVqNGjawlS5a49HH8+HGrU6dOVkhISJ7pS/Oj/z/d7JX8frrZrKwsq0SJElbz5s2v+JyYmBgrLi7O+d4K+u5KskaNGnXF12rZsqVVs2ZNa/v27Vbjxo2twMBAKzo62nrjjTcKfE7Hjh0tSdZnn312xdfOVdBxklv70qVLXdYXdLy/8cYbVrVq1azChQtbZcqUsR5//HHrzJkzefp78803rZiYGMtut1sNGjSwNm3alO/3Kysry5owYYJVs2ZNy263W8WLF7fq169vjRkzxkpPT3e2Y7pZ4OZjsywPXqUFADeZIUOGaPr06Tp//nyBF7cC3tC9e3ft3r37uq4DAoAbiWssANy2Lp/B6tSpU5o3b56aNWtGqIBPOXbsmN577z099NBD3i4FAArENRYAbluNGzdWq1atVL16dZ04cUIzZ85URkbGFS/yBW6kw4cP69NPP9WMGTNUuHBhlxvqAYCvIVgAuG117NhRy5Yt01tvvSWbzaY777xTM2fOVIsWLbxdGiBJ2rhxo/r3768KFSpo7ty5brtxIAB4AtdYAAAAADDGNRYAAAAAjBEsAAAAABjzuWsscnJydPToUYWEhFzTDaoAAAAAeIZlWTp37pwiIyPl53flMQmfCxZHjx5VVFSUt8sAAAAA8P+lpaWpfPnyV2zjc8EiJCRE0m/Fh4aGerkaAAAA4PaVkZGhqKgo52/0K/G5YJF7+lNoaCjBAgAAAPAB13KJAhdvAwAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGPO5G+TlqjVqjfzsRbxdBgAAAHDDHRnfydslXDdGLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGPBYspU6aoYsWKCgwMVKNGjfTFF194qisAAAAAXuaRYPHOO+9o2LBhGjVqlL788kvVrVtX8fHxOnnypCe6AwAAAOBlHgkWr732mgYNGqT+/furRo0amjZtmooUKaJZs2Z5ojsAAAAAXub2YJGVlaUdO3aoXbt2/9eJn5/atWunLVu25GnvcDiUkZHhsgAAAAC4ubg9WPz888/Kzs5WmTJlXNaXKVNGx48fz9M+JSVFYWFhziUqKsrdJQEAAADwMK/PCpWcnKz09HTnkpaW5u2SAAAAAFynQu5+wZIlS8rf318nTpxwWX/ixAlFRETkaW+322W3291dBgAAAIAbyO0jFgEBAapfv74++ugj57qcnBx99NFHaty4sbu7AwAAAOAD3D5iIUnDhg1TYmKiGjRooIYNG2rSpEnKzMxU//79PdEdAAAAAC/zSLDo1auXfvrpJ7300ks6fvy46tWrpw8++CDPBd0AAAAAbg0eCRaS9OSTT+rJJ5/01MsDAAAA8CFenxUKAAAAwM2PYAEAAADAGMECAAAAgDGCBQAAAABjHrt429SeMfEKDQ31dhkAAAAArgEjFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgrJC3CyhIrVFr5Gcv4u0yAAAAgBvuyPhO3i7hujFiAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjLk9WGzatEldunRRZGSkbDabVq5c6e4uAAAAAPgYtweLzMxM1a1bV1OmTHH3SwMAAADwUW6/j0VCQoISEhLc/bIAAAAAfJjXb5DncDjkcDicjzMyMrxYDQAAAIA/wusXb6ekpCgsLMy5REVFebskAAAAANfJ68EiOTlZ6enpziUtLc3bJQEAAAC4Tl4/Fcput8tut3u7DAAAAAAGvD5iAQAAAODm5/YRi/Pnz+vgwYPOx4cPH9auXbsUHh6uChUquLs7AAAAAD7A7cFi+/btat26tfPxsGHDJEmJiYmaM2eOu7sDAAAA4APcHixatWoly7Lc/bIAAAAAfBjXWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMa/fIK8ge8bEKzQ01NtlAAAAALgGjFgAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgLFC3i6gILVGrZGfvYi3ywAAAABuuCPjO3m7hOvGiAUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADDm9mAxdepU1alTR6GhoQoNDVXjxo21evVqd3cDAAAAwIe4PViUL19e48eP144dO7R9+3a1adNGXbt21d69e93dFQAAAAAf4fb7WHTp0sXl8csvv6ypU6dq69atqlmzpru7AwAAAOADPHqDvOzsbC1dulSZmZlq3Lhxvm0cDoccDofzcUZGhidLAgAAAOABHrl4e/fu3SpatKjsdrsee+wxrVixQjVq1Mi3bUpKisLCwpxLVFSUJ0oCAAAA4EEeCRZVq1bVrl279Pnnn+vxxx9XYmKivv7663zbJicnKz093bmkpaV5oiQAAAAAHuSRU6ECAgJUuXJlSVL9+vW1bds2/fOf/9T06dPztLXb7bLb7Z4oAwAAAMANckPuY5GTk+NyHQUAAACAW4vbRyySk5OVkJCgChUq6Ny5c1q4cKE2bNigNWvWuLsrAAAAAD7C7cHi5MmTevjhh3Xs2DGFhYWpTp06WrNmje6++253dwUAAADAR7g9WMycOdPdLwkAAADAx92QaywAAAAA3NoIFgAAAACMESwAAAAAGCNYAAAAADDmkRvkucOeMfEKDQ31dhkAAAAArgEjFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgrJC3CyhIrVFr5Gcv4u0yAAAAgBvmyPhO3i7hD2PEAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGHN7sEhJSdFdd92lkJAQlS5dWt26ddO+ffvc3Q0AAAAAH+L2YLFx40YlJSVp69atWrt2rS5duqT27dsrMzPT3V0BAAAA8BFuv4/FBx984PJ4zpw5Kl26tHbs2KEWLVq4uzsAAAAAPsDjN8hLT0+XJIWHh+e73eFwyOFwOB9nZGR4uiQAAAAAbubRi7dzcnI0ZMgQNW3aVLVq1cq3TUpKisLCwpxLVFSUJ0sCAAAA4AEeDRZJSUnas2ePFi9eXGCb5ORkpaenO5e0tDRPlgQAAADAAzx2KtSTTz6p//73v9q0aZPKly9fYDu73S673e6pMgAAAADcAG4PFpZl6amnntKKFSu0YcMGxcTEuLsLAAAAAD7G7cEiKSlJCxcu1LvvvquQkBAdP35ckhQWFqagoCB3dwcAAADAB7j9GoupU6cqPT1drVq1UtmyZZ3LO++84+6uAAAAAPgIj5wKBQAAAOD24tFZoQAAAADcHggWAAAAAIwRLAAAAAAYI1gAAAAAMOaxG+SZ2jMmXqGhod4uAwAAAMA1YMQCAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwV8nYBBak1ao387EW8XQYAAABukCPjO3m7BBhgxAIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABjzSLD48ccf1bdvX5UoUUJBQUGqXbu2tm/f7omuAAAAAPgAt083e+bMGTVt2lStW7fW6tWrVapUKR04cEDFixd3d1cAAAAAfITbg8WECRMUFRWl2bNnO9fFxMS4uxsAAAAAPsTtp0KtWrVKDRo00P3336/SpUsrLi5Ob7/9doHtHQ6HMjIyXBYAAAAANxe3B4vvvvtOU6dOVZUqVbRmzRo9/vjjevrppzV37tx826ekpCgsLMy5REVFubskAAAAAB5msyzLcucLBgQEqEGDBvrss8+c655++mlt27ZNW7ZsydPe4XDI4XA4H2dkZCgqKkpRQ5bIz17EnaUBAADAhx0Z38nbJeAyGRkZCgsLU3p6ukJDQ6/Y1u0jFmXLllWNGjVc1lWvXl2pqan5trfb7QoNDXVZAAAAANxc3B4smjZtqn379rms279/v6Kjo93dFQAAAAAf4fZgMXToUG3dulV/+9vfdPDgQS1cuFBvvfWWkpKS3N0VAAAAAB/h9mBx1113acWKFVq0aJFq1aqlsWPHatKkSerTp4+7uwIAAADgI9x+HwtJ6ty5szp37uyJlwYAAADgg9w+YgEAAADg9kOwAAAAAGCMYAEAAADAGMECAAAAgDGPXLztDnvGxHOzPAAAAOAmwYgFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgjWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgjWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgr5O0CClJr1Br52Yt4uwwAAAAYODK+k7dLwA3CiAUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADDm8WAxfvx42Ww2DRkyxNNdAQAAAPASjwaLbdu2afr06apTp44nuwEAAADgZR4LFufPn1efPn309ttvq3jx4p7qBgAAAIAP8FiwSEpKUqdOndSuXTtPdQEAAADAR3jkztuLFy/Wl19+qW3btl21rcPhkMPhcD7OyMjwREkAAAAAPMjtIxZpaWl65plntGDBAgUGBl61fUpKisLCwpxLVFSUu0sCAAAA4GE2y7Isd77gypUr1b17d/n7+zvXZWdny2azyc/PTw6Hw2VbfiMWUVFRihqyRH72Iu4sDQAAADfYkfGdvF0CDGRkZCgsLEzp6ekKDQ29Ylu3nwrVtm1b7d6922Vd//79Va1aNT3//PMuoUKS7Ha77Ha7u8sAAAAAcAO5PViEhISoVq1aLuuCg4NVokSJPOsBAAAA3Bq48zYAAAAAYx6ZFepyGzZsuBHdAAAAAPASRiwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwNgNuXj7j9gzJv6qN+EAAAAA4BsYsQAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAY4W8XUBBao1aIz97EW+XAQAA4LOOjO/k7RIAJ0YsAAAAABgjWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAsesOFps2bVKXLl0UGRkpm82mlStXumy3LEsvvfSSypYtq6CgILVr104HDhxwV70AAAAAfNB1B4vMzEzVrVtXU6ZMyXf7xIkTNXnyZE2bNk2ff/65goODFR8fr4sXLxoXCwAAAMA3Xfd9LBISEpSQkJDvNsuyNGnSJP3lL39R165dJUn/+te/VKZMGa1cuVIPPPCAWbUAAAAAfJJbr7E4fPiwjh8/rnbt2jnXhYWFqVGjRtqyZYs7uwIAAADgQ9x65+3jx49LksqUKeOyvkyZMs5tl3M4HHI4HM7HGRkZ7iwJAAAAwA3g9VmhUlJSFBYW5lyioqK8XRIAAACA6+TWYBERESFJOnHihMv6EydOOLddLjk5Wenp6c4lLS3NnSUBAAAAuAHcGixiYmIUERGhjz76yLkuIyNDn3/+uRo3bpzvc+x2u0JDQ10WAAAAADeX677G4vz58zp48KDz8eHDh7Vr1y6Fh4erQoUKGjJkiMaNG6cqVaooJiZGI0eOVGRkpLp16+bOugEAAAD4kOsOFtu3b1fr1q2dj4cNGyZJSkxM1Jw5czRixAhlZmbq0Ucf1dmzZ9WsWTN98MEHCgwMdF/VAAAAAHyKzbIsy9tF/F5GRsZvF3EPWSI/exFvlwMAAOCzjozv5O0ScIvL/W2enp5+1UsWvD4rFAAAAICbH8ECAAAAgDGCBQAAAABjBAsAAAAAxq57VqgbZc+YeO5pAQAAANwkGLEAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgjWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgjWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGOFvF1AQWqNWiM/exFvlwEAAOCTjozv5O0SABeMWAAAAAAwRrAAAAAAYIxgAQAAAMAYwQIAAACAMYIFAAAAAGNuDxbZ2dkaOXKkYmJiFBQUpNjYWI0dO1aWZbm7KwAAAAA+wu3TzU6YMEFTp07V3LlzVbNmTW3fvl39+/dXWFiYnn76aXd3BwAAAMAHuD1YfPbZZ+ratas6dfptbuWKFStq0aJF+uKLL9zdFQAAAAAf4fZToZo0aaKPPvpI+/fvlyT973//0+bNm5WQkODurgAAAAD4CLePWLzwwgvKyMhQtWrV5O/vr+zsbL388svq06dPvu0dDoccDofzcUZGhrtLAgAAAOBhbh+xWLJkiRYsWKCFCxfqyy+/1Ny5c/XKK69o7ty5+bZPSUlRWFiYc4mKinJ3SQAAAAA8zGa5ebqmqKgovfDCC0pKSnKuGzdunObPn69vv/02T/v8RiyioqIUNWSJ/OxF3FkaAADALePI+E7eLgG3gYyMDIWFhSk9PV2hoaFXbOv2U6EuXLggPz/XgRB/f3/l5OTk295ut8tut7u7DAAAAAA3kNuDRZcuXfTyyy+rQoUKqlmzpnbu3KnXXntNAwYMcHdXAAAAAHyE24PF66+/rpEjR+qJJ57QyZMnFRkZqcGDB+ull15yd1cAAAAAfITbg0VISIgmTZqkSZMmufulAQAAAPgot88KBQAAAOD2Q7AAAAAAYIxgAQAAAMAYwQIAAACAMbdfvO0ue8bEX/UmHAAAAAB8AyMWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCskLcLKEitUWvkZy/i7TIAAAB8xpHxnbxdAlAgRiwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxtweLihUrymaz5VmSkpLc3RUAAAAAH+H26Wa3bdum7Oxs5+M9e/bo7rvv1v333+/urgAAAAD4CLcHi1KlSrk8Hj9+vGJjY9WyZUt3dwUAAADAR3j0GousrCzNnz9fAwYMkM1m82RXAAAAALzIo3feXrlypc6ePat+/foV2MbhcMjhcDgfZ2RkeLIkAAAAAB7g0RGLmTNnKiEhQZGRkQW2SUlJUVhYmHOJioryZEkAAAAAPMBjweL777/XunXrNHDgwCu2S05OVnp6unNJS0vzVEkAAAAAPMRjp0LNnj1bpUuXVqdOna7Yzm63y263e6oMAAAAADeAR0YscnJyNHv2bCUmJqpQIY9exgEAAADAB3gkWKxbt06pqakaMGCAJ14eAAAAgI/xyHBC+/btZVmWJ14aAAAAgA/y6KxQAAAAAG4PBAsAAAAAxggWAAAAAIwRLAAAAAAY89m5YPeMiVdoaKi3ywAAAABwDRixAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjhbxdQEFqjVojP3sRb5cBAADgNUfGd/J2CcA1Y8QCAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYu+5gsWnTJnXp0kWRkZGy2WxauXKly/Z///vfat++vUqUKCGbzaZdu3a5qVQAAAAAvuq6g0VmZqbq1q2rKVOmFLi9WbNmmjBhgnFxAAAAAG4O130fi4SEBCUkJBS4/aGHHpIkHTly5A8XBQAAAODmwjUWAAAAAIx5/c7bDodDDofD+TgjI8OL1QAAAAD4I7w+YpGSkqKwsDDnEhUV5e2SAAAAAFwnrweL5ORkpaenO5e0tDRvlwQAAADgOnn9VCi73S673e7tMgAAAAAYuO5gcf78eR08eND5+PDhw9q1a5fCw8NVoUIFnT59WqmpqTp69Kgkad++fZKkiIgIRUREuKlsAAAAAL7kuk+F2r59u+Li4hQXFydJGjZsmOLi4vTSSy9JklatWqW4uDh16tRJkvTAAw8oLi5O06ZNc2PZAAAAAHyJzbIsy9tF/F5GRsZvF3EPWSI/exFvlwMAAOA1R8Z38nYJuM3l/jZPT09XaGjoFdt6/eJtAAAAADc/ggUAAAAAYwQLAAAAAMYIFgAAAACMef0+FgXZMyb+qheIAAAAAPANjFgAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgLFC3i6gILVGrZGfvYi3ywAAAPCKI+M7ebsE4LowYgEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxggWAAAAAIx5JFicO3dOQ4YMUXR0tIKCgtSkSRNt27bNE10BAAAA8AEeCRYDBw7U2rVrNW/ePO3evVvt27dXu3bt9OOPP3qiOwAAAABe5vZg8csvv2j58uWaOHGiWrRoocqVK2v06NGqXLmypk6d6u7uAAAAAPgAtweLX3/9VdnZ2QoMDHRZHxQUpM2bN7u7OwAAAAA+wO3BIiQkRI0bN9bYsWN19OhRZWdna/78+dqyZYuOHTuWp73D4VBGRobLAgAAAODm4pFrLObNmyfLslSuXDnZ7XZNnjxZvXv3lp9f3u5SUlIUFhbmXKKiojxREgAAAAAP8kiwiI2N1caNG3X+/HmlpaXpiy++0KVLl1SpUqU8bZOTk5Wenu5c0tLSPFESAAAAAA8q5MkXDw4OVnBwsM6cOaM1a9Zo4sSJedrY7XbZ7XZPlgEAAADAwzwSLNasWSPLslS1alUdPHhQzz33nKpVq6b+/ft7ojsAAAAAXuaRU6HS09OVlJSkatWq6eGHH1azZs20Zs0aFS5c2BPdAQAAAPAyj4xY9OzZUz179vTESwMAAADwQR4ZsQAAAABweyFYAAAAADBGsAAAAABgjGABAAAAwJhH72NhYs+YeIWGhnq7DAAAAADXgBELAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACMESwAAAAAGCNYAAAAADBWyNsFFKTWqDXysxfxdhkAAABXdGR8J2+XAPgERiwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxtweL0aNHy2azuSzVqlVzdzcAAAAAfIhHpputWbOm1q1b93+dFPLZWW0BAAAAuIFHfvEXKlRIERERnnhpAAAAAD7II9dYHDhwQJGRkapUqZL69Omj1NRUT3QDAAAAwEe4fcSiUaNGmjNnjqpWrapjx45pzJgxat68ufbs2aOQkJA87R0OhxwOh/NxRkaGu0sCAAAA4GFuDxYJCQnOf9epU0eNGjVSdHS0lixZokceeSRP+5SUFI0ZM8bdZQAAAAC4gTw+3WyxYsV0xx136ODBg/luT05OVnp6unNJS0vzdEkAAAAA3MzjweL8+fM6dOiQypYtm+92u92u0NBQlwUAAADAzcXtwWL48OHauHGjjhw5os8++0zdu3eXv7+/evfu7e6uAAAAAPgIt19j8cMPP6h37946deqUSpUqpWbNmmnr1q0qVaqUu7sCAAAA4CPcHiwWL17s7pcEAAAA4OM8fo0FAAAAgFsfwQIAAACAMYIFAAAAAGMECwAAAADG3H7xtrvsGRPPPS0AAACAmwQjFgAAAACMESwAAAAAGCNYAAAAADBGsAAAAABgjGABAAAAwBjBAgAAAIAxggUAAAAAYwQLAAAAAMYIFgAAAACM+dydty3LkiRlZGR4uRIAAADg9pb7mzz3N/qV+FywOHXqlCQpKirKy5UAAAAAkKRz584pLCzsim18LliEh4dLklJTU69aPHxfRkaGoqKilJaWptDQUG+XA0Psz1sL+/PWwv68dbAvby03+/60LEvnzp1TZGTkVdv6XLDw8/vtso+wsLCb8sNH/kJDQ9mftxD2562F/XlrYX/eOtiXt5abeX9e6x/7uXgbAAAAgDGCBQAAAABjPhcs7Ha7Ro0aJbvd7u1S4Absz1sL+/PWwv68tbA/bx3sy1vL7bQ/bda1zB0FAAAAAFfgcyMWAAAAAG4+BAsAAAAAxggWAAAAAIz5XLCYMmWKKlasqMDAQDVq1EhffPGFt0vCHzB69GjZbDaXpVq1at4uC9do06ZN6tKliyIjI2Wz2bRy5UqX7ZZl6aWXXlLZsmUVFBSkdu3a6cCBA94pFld1tf3Zr1+/PMdrhw4dvFMsriglJUV33XWXQkJCVLp0aXXr1k379u1zaXPx4kUlJSWpRIkSKlq0qO677z6dOHHCSxXjSq5lf7Zq1SrP8fnYY495qWIUZOrUqapTp47zXhWNGzfW6tWrndtvl+PSp4LFO++8o2HDhmnUqFH68ssvVbduXcXHx+vkyZPeLg1/QM2aNXXs2DHnsnnzZm+XhGuUmZmpunXrasqUKflunzhxoiZPnqxp06bp888/V3BwsOLj43Xx4sUbXCmuxdX2pyR16NDB5XhdtGjRDawQ12rjxo1KSkrS1q1btXbtWl26dEnt27dXZmams83QoUP1n//8R0uXLtXGjRt19OhR3XvvvV6sGgW5lv0pSYMGDXI5PidOnOililGQ8uXLa/z48dqxY4e2b9+uNm3aqGvXrtq7d6+k2+i4tHxIw4YNraSkJOfj7OxsKzIy0kpJSfFiVfgjRo0aZdWtW9fbZcANJFkrVqxwPs7JybEiIiKsv//97851Z8+etex2u7Vo0SIvVIjrcfn+tCzLSkxMtLp27eqVemDm5MmTliRr48aNlmX9diwWLlzYWrp0qbPNN998Y0mytmzZ4q0ycY0u35+WZVktW7a0nnnmGe8VhT+sePHi1owZM26r49JnRiyysrK0Y8cOtWvXzrnOz89P7dq105YtW7xYGf6oAwcOKDIyUpUqVVKfPn2Umprq7ZLgBocPH9bx48ddjtWwsDA1atSIY/UmtmHDBpUuXVpVq1bV448/rlOnTnm7JFyD9PR0SVJ4eLgkaceOHbp06ZLL8VmtWjVVqFCB4/MmcPn+zLVgwQKVLFlStWrVUnJysi5cuOCN8nCNsrOztXjxYmVmZqpx48a31XFZyNsF5Pr555+VnZ2tMmXKuKwvU6aMvv32Wy9VhT+qUaNGmjNnjqpWrapjx45pzJgxat68ufbs2aOQkBBvlwcDx48fl6R8j9Xcbbi5dOjQQffee69iYmJ06NAhvfjii0pISNCWLVvk7+/v7fJQgJycHA0ZMkRNmzZVrVq1JP12fAYEBKhYsWIubTk+fV9++1OSHnzwQUVHRysyMlJfffWVnn/+ee3bt0///ve/vVgt8rN79241btxYFy9eVNGiRbVixQrVqFFDu3btum2OS58JFri1JCQkOP9dp04dNWrUSNHR0VqyZIkeeeQRL1YG4HIPPPCA89+1a9dWnTp1FBsbqw0bNqht27ZerAxXkpSUpD179nD92i2ioP356KOPOv9du3ZtlS1bVm3bttWhQ4cUGxt7o8vEFVStWlW7du1Senq6li1bpsTERG3cuNHbZd1QPnMqVMmSJeXv75/nCvkTJ04oIiLCS1XBXYoVK6Y77rhDBw8e9HYpMJR7PHKs3roqVaqkkiVLcrz6sCeffFL//e9/tX79epUvX965PiIiQllZWTp79qxLe45P31bQ/sxPo0aNJInj0wcFBASocuXKql+/vlJSUlS3bl3985//vK2OS58JFgEBAapfv74++ugj57qcnBx99NFHaty4sRcrgzucP39ehw4dUtmyZb1dCgzFxMQoIiLC5VjNyMjQ559/zrF6i/jhhx906tQpjlcfZFmWnnzySa1YsUIff/yxYmJiXLbXr19fhQsXdjk+9+3bp9TUVI5PH3S1/ZmfXbt2SRLH500gJydHDofjtjoufepUqGHDhikxMVENGjRQw4YNNWnSJGVmZqp///7eLg3Xafjw4erSpYuio6N19OhRjRo1Sv7+/urdu7e3S8M1OH/+vMtfww4fPqxdu3YpPDxcFSpU0JAhQzRu3DhVqVJFMTExGjlypCIjI9WtWzfvFY0CXWl/hoeHa8yYMbrvvvsUERGhQ4cOacSIEapcubLi4+O9WDXyk5SUpIULF+rdd99VSEiI8/zssLAwBQUFKSwsTI888oiGDRum8PBwhYaG6qmnnlLjxo31pz/9ycvV43JX25+HDh3SwoUL1bFjR5UoUUJfffWVhg4dqhYtWqhOnTperh6/l5ycrISEBFWoUEHnzp3TwoULtWHDBq1Zs+b2Oi69PS3V5V5//XWrQoUKVkBAgNWwYUNr69at3i4Jf0CvXr2ssmXLWgEBAVa5cuWsXr16WQcPHvR2WbhG69evtyTlWRITEy3L+m3K2ZEjR1plypSx7Ha71bZtW2vfvn3eLRoFutL+vHDhgtW+fXurVKlSVuHCha3o6Ghr0KBB1vHjx71dNvKR336UZM2ePdvZ5pdffrGeeOIJq3jx4laRIkWs7t27W8eOHfNe0SjQ1fZnamqq1aJFCys8PNyy2+1W5cqVreeee85KT0/3buHIY8CAAVZ0dLQVEBBglSpVymrbtq314YcfOrffLselzbIs60YGGQAAAAC3Hp+5xgIAAADAzYtgAQAAAMAYwQIAAACAMYIFAAAAAGMECwAAAADGCBYAAAAAjBEsAAAAABgjWAAAAAAwRrAAAHhVixYttHDhwhvS1+jRo1WvXj23vFZWVpYqVqyo7du3u+X1AOBmR7AAgBvIZrNdcRk9erTRa69cufKaa9i6davLeofDoRIlSshms2nDhg15njd48GD5+/tr6dKlebaNHj063/dTrVq1K9ayatUqnThxQg888MBV6/Y1AQEBGj58uJ5//nlvlwIAPoFgAQA30LFjx5zLpEmTFBoa6rJu+PDhN6SOqKgozZ4922XdihUrVLRo0XzbX7hwQYsXL9aIESM0a9asfNvUrFnT5b0cO3ZMmzdvvmIdkydPVv/+/eXnd3P+31GfPn20efNm7d2719ulAIDX3Zz/JQeAm1RERIRzCQsLk81mc1m3ePFiVa9eXYGBgapWrZrefPNN53OzsrL05JNPqmzZsgoMDFR0dLRSUlIkSRUrVpQkde/eXTabzfm4IImJiVq8eLF++eUX57pZs2YpMTEx3/ZLly5VjRo19MILL2jTpk1KS0vL06ZQoUIu7yUiIkIlS5YssIaffvpJH3/8sbp06eKy/uzZsxo8eLDKlCmjwMBA1apVS//973+VmZmp0NBQLVu2zKX9ypUrFRwcrHPnzkmSfvjhB/Xu3Vvh4eEKDg5WgwYN9PnnnxdYx4wZM/7QZy5JxYsXV9OmTbV48eICXx8AbheFvF0AAOA3CxYs0EsvvaQ33nhDcXFx2rlzpwYNGqTg4GAlJiZq8uTJWrVqlZYsWaIKFSooLS3N+QN/27ZtKl26tGbPnq0OHTrI39//in3Vr19fFStW1PLly9W3b1+lpqZq06ZNmjJlisaOHZun/cyZM9W3b1+FhYUpISFBc+bM0ciRI43e7+bNm1WkSBFVr17duS4nJ0cJCQk6d+6c5s+fr9jYWH399dfy9/dXcHCwHnjgAc2ePVs9evRwPif3cUhIiM6fP6+WLVuqXLlyWrVqlSIiIvTll18qJycn3xpMPvNcDRs21CeffGL0WQDArYBgAQA+YtSoUXr11Vd17733SpJiYmL09ddfa/r06UpMTFRqaqqqVKmiZs2ayWazKTo62vncUqVKSZKKFSumiIiIa+pvwIABmjVrlvr27as5c+aoY8eOztf5vQMHDmjr1q3697//LUnq27evhg0bpr/85S+y2WzOdrt3785zKlXfvn01bdq0fPv//vvvVaZMGZfToNatW6cvvvhC33zzje644w5JUqVKlZzbBw4cqCZNmujYsWMqW7asTp48qffff1/r1q2TJC1cuFA//fSTtm3bpvDwcElS5cqVC/wMTD7zXJGRkfr+++8L7AMAbhecCgUAPiAzM1OHDh3SI488oqJFizqXcePG6dChQ5Kkfv36adeuXapataqefvppffjhh0Z99u3bV1u2bNF3332nOXPmaMCAAfm2mzVrluLj452nNXXs2FHp6en6+OOPXdpVrVpVu3btcln++te/Ftj/L7/8osDAQJd1u3btUvny5Z2h4nINGzZUzZo1NXfuXEnS/PnzFR0drRYtWjifHxcX5wwVV+KuzzwoKEgXLly4an8AcKtjxAIAfMD58+clSW+//bYaNWrksi33tKY777xThw8f1urVq7Vu3Tr17NlT7dq1y3PNwbUqUaKEOnfurEceeUQXL150noL0e9nZ2Zo7d66OHz+uQoUKuayfNWuW2rZt61wXEBBwxdGBy5UsWVJnzpxxWRcUFHTV5w0cOFBTpkzRCy+8oNmzZ6t///7OkZNreX4ud33mp0+fznekBwBuNwQLAPABZcqUUWRkpL777jv16dOnwHahoaHq1auXevXqpR49eqhDhw46ffq0wsPDVbhwYWVnZ19XvwMGDFDHjh31/PPP53tdxvvvv69z585p586dLtv37Nmj/v376+zZsypWrNh19ZkrLi5Ox48f15kzZ1S8eHFJUp06dfTDDz9o//79BY5a9O3bVyNGjNDkyZP19ddfu1xwXqdOHc2YMcP5mVyJOz5z6bfPIi4u7nrfPgDccggWAOAjxowZo6efflphYWHq0KGDHA6Htm/frjNnzmjYsGF67bXXVLZsWcXFxcnPz09Lly5VRESE84d9xYoV9dFHH6lp06ay2+3OH+tX0qFDB/30008KDQ3Nd/vMmTPVqVMn1a1b12V9jRo1NHToUC1YsEBJSUmSpF9//VXHjx93aWez2VSmTJl8XzsuLk4lS5bUp59+qs6dO0uSWrZsqRYtWui+++7Ta6+9psqVK+vbb7+VzWZThw4dJP02E9O9996r5557Tu3bt1f58uWdr9m7d2/97W9/U7du3ZSSkqKyZctq586dioyMVOPGjd3+mUvSJ598ku8F7wBwu+EaCwDwEQMHDtSMGTM0e/Zs1a5dWy1bttScOXMUExMjSQoJCdHEiRPVoEED3XXXXTpy5Ijef/9958XPr776qtauXauoqKhr/gu6zWZTyZIlFRAQkGfbiRMn9N577+m+++7Ls83Pz0/du3fXzJkznev27t2rsmXLuiz5Xeycy9/fX/3799eCBQtc1i9fvlx33XWXevfurRo1amjEiBF5RmIeeeQRZWVl5bkuJCAgQB9++KFKly6tjh07qnbt2ho/fnyBs2SZfuZbtmxRenq6yyxVAHC7slmWZXm7CADA7en48eOqWbOmvvzyyyuGkMvNmzdPQ4cO1dGjR/MNRTdKr169VLduXb344oteqwEAfAUjFgAAr4mIiNDMmTOVmpp6Te0vXLigQ4cOafz48Ro8eLBXQ0VWVpZq166toUOHeq0GAPAljFgAAG4ao0eP1ssvv6wWLVro3XffzXPfDACA9xAsAAAAABjjVCgAAAAAxggWAAAAAIwRLAAAAAAYI1gAAAAAMEawAAAAAGCMYAEAAADAGMECAAAAgDGCBQAAAABjBAsAAAAAxv4f+xIxSvmNmSgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-XHR0GzJD11J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}